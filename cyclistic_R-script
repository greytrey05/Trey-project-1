
       
# start by installing the add-ons 

library('tidyverse')    -> tidyverse for data import and wrangling
library("lubridate")    -> lubridate for date functions
library('ggplot2')      -> ggplot for visualization
library('dplyr)         -> for data manipulation


getwd()                 -> displays your working directory

"C:/Users/james/OneDrive/Documents/R/cyclistic"

# STEP 1 COLLECT DATA             ## upload divvy datasets (csv files)

library(readr)


x202201 <- read_delim("cyclistic/202201-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)


x202202 <- read_delim("cyclistic/202202-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)



x202203 <- read_delim("Nouveau dossier/202203-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)


x202204 <- read_delim("Nouveau dossier/202204-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)


x202205 <- read_delim("Nouveau dossier/202205-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)


x202206 <- read_delim("Nouveau dossier/202206-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)


x202207 <- read_delim("Nouveau dossier/202207-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)


x202208 <- read_delim("Nouveau dossier/202208-divvy-tripdata.csv", 
                      delim = ";", escape_double = FALSE, trim_ws = TRUE)
                      
                                            
 # STEP 2: WRANGLE DATA AND COMBINE INTO A SINGLE FILE

         

                                             ## Stack data frames into one big data frame

year_2022 <- rbind(x202201, x202202, x202203, x202204, x202205, x202206, x202207, x202208, x202209, x202210, x202211, x202212)


# STEP 3: CLEAN UP AND ADD DATA TO PREPARE FOR ANALYSIS

 ## Getting a summary of the new file
 
 colnames(year_2022)
 glimpse(year_2022)
 head(year_2022)
 
 ## looking for how many missing values there is in the dataset year_2022
 sum(is.na(year_2022))
 
 ## looking for what exact columns have missing values
colsums(is.na(year_2022)

## clean the missing values
year_2022_V2 <- na.omit(year_2022)

## Inspect the new table that has been created

colnames(year_2022_V2)
names(year_2022_V2)
length(year_2022_V2)

## List of column names

nrow(year_2022_V2)

## How many rows are in data frame

dim(year_2022_V2)

## Dimensions of the data frame

head(year_2022_V2)

#See the first 6 rows of data frame

tail(year_2022_V2)

## See list of columns and data types

str(year_2022_V2)

summary(year_2022_V2)

The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data 
-- such as day, month, year -- that provide additional opportunities to aggregate the data.

## Add columns that list the date, month, day, and year of each ride

year_2022_v2$date <- as.Date(year_2022_v2$started_at) 
year_2022_v2$month <- format(as.Date(year_2022_v2$date), "%m")
year_2022_v2$day <- format(as.Date(year_2022_v2$date), "%d")
year_2022_v2$year <- format(as.Date(year_2022_v2$date), "%Y")
year_2022_v2$day_of_week <- format(as.Date(year_2022_v2$date), "%A")

glimpse(year_2022_v2)

## Add a "ride_length" calculation to all_trips (in seconds)
because I had to create in excel "ride_length" to do some calculation I need to create a new "ride_length" with R and delete the previous one

year_2022_v2$ride_length = null      <- delete ride_length 

year_2022_v2$ride_length <- difftime(year_2022_v2$ended_at,year_2022_v2$started_at)      <- new ride_length created with R

## Inspect the structure of the columns

str(year_2022_v2)

## Convert "ride_length" from Factor to numeric so we can run calculations on the data

is.factor(year_2022_v2$ride_length)
year_2022_v2$ride_length <- as.numeric(as.character(year_2022_v2$ride_length))
is.numeric(year_2022_v2$ride_length)


## Remove "bad" data
## The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality by Divvy or ride_length was negative
## We will create a new version of the dataframe (v2) since data is being removed

year_2022_v3 <- year_2022_v2[!(year_2022_v2$start_station_name == "HQ QR" | year_2022_v2$ride_length<0),]

## Remove "bad" data

sum(is.na(year_2022_v3))
str(full_year_cleaned_V04)

# STEP 4: CONDUCT DESCRIPTIVE ANALYSIS

## Descriptive analysis on ride_length (all figures in seconds)

mean(year_2022_v3$ride_length) #straight average (total ride length / rides)
median(year_2022_v3$ride_length) #midpoint number in the ascending array of ride lengths
max(year_2022_v3$ride_length) #longest ride
min(year_2022_v3$ride_length) #shortest ride
                                                 
## Compare members and casual users

aggregate(year_2022_v3$ride_length ~ year_2022_v3$member_casual, FUN = mean)
aggregate(year_2022_v3$ride_length ~ year_2022_v3$member_casual, FUN = median)
aggregate(year_2022_v3$ride_length ~ year_2022_v3$member_casual, FUN = max)
aggregate(year_2022_v3$ride_length ~ year_2022_v3$member_casual, FUN = min)

## the average ride time by each day for members vs casual users
aggregate(year_2022_v3$ride_length ~ year_2022_v3$member_casual + year_2022_v3$day_of_week, FUN = mean)
                         
## Notice that the days of the week are out of order. Let's fix that.
year_2022_v3$day_of_week <- ordered(year_2022_v3$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

## the average ride time by each day for members vs casual users
aggregate(year_2022_v3$ride_length ~ year_2022_v3$member_casual + year_2022_v3$day_of_week, FUN = mean)


## analyze ridership data by type and weekday
year_2022_v3 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
  ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)								# sorts


## Viz for the number of rides by rider type
year_2022_v3 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")

# Viz for average duration
year_2022_v3 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")


# STEP 5: EXPORT SUMMARY FILE FOR FURTHER ANALYSIS

counts <- aggregate(year_2022_v3$ride_length ~ year_2022_v3$member_casual + year_2022_v3$day_of_week, FUN = mean)

View(counts)

write.csv(counts, "~/R/cyclistic/counts.csv", row.names=TRUE)
write.csv(year_2022_v3, "~/R/cyclistic/year_2022.csv", row.names=TRUE)
